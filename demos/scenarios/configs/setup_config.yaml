assistant_llm:
  # put the unique_model_id that you specified in llm_config.yaml
  prompt_opt: Pro/deepseek-ai/DeepSeek-V3
dir_info:
  # Base directory for everything
  base_dir: logs
  log_dir_name: glue_logs
experiment_name: gsm8k
# Many features are different for mode: online/offline. For eg
# 1) Print of logs happens on console for offline mode
# 2) LLM Queue gets instantiated only in online mode
mode: offline
# Full length description of the experiment. This would be logged.
description:
